#-*-coding:utf8-*-
#抓取百度贴吧回帖时间，回帖人，回帖内容信息http://tieba.baidu.com/p/3522395718
from lxml import etree
from multiprocessing.dummy import Pool as ThreadPool
import requests,json
import sys
reload(sys)
sys.setdefaultencoding('utf8')
def towrite(contentdict):
    f.writelines(u'回帖时间:'+str(contentdict['topic_reply_time'])+'\n')
    f.writelines(u'回帖内容:'+str(contentdict['topic_reply_content'])+'\n')
    f.writelines(u'回帖时人:'+str(contentdict['user_name'])+'\n\n')
def  spider(url):
    html=requests.get(url)
    selector=etree.HTML(html.text)
    content_field=selector.xpath('//div[@class="l_post j_l_post l_post_bright  "]')
    item={}
    for each in content_field:
        reply_info=json.loads(each.xpath('@data-field')[0])
        author=reply_info['author']['user_name']
        content=each.xpath('div[@class="d_post_content_main"]/div/cc/div[@class="d_post_content j_d_post_content  clearfix"]')[0]
        content=content.xpath('string()')
        reply_time=reply_info['content']['date']
        item['user_name']=author
        item['topic_reply_content']=content
        item['topic_reply_time']=reply_time
        towrite(item)


if __name__=="__main__":
    pool=ThreadPool(4)
    f=open('content.txt','a')
    page=[]
    for i in range(21):
        url="http://tieba.baidu.com/p/3522395718?pn="+str(i)
        page.append(url)
    result=pool.map(spider,page)
    pool.close()
    pool.join()
    f.close()
